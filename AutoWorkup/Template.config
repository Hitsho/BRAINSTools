# The intent of this configuraiton file is to define all the information needed to completely run an experiment.
#
[EXPERIMENT]
#   A formatted csv file decribing the data sets one per line, where the different data types are listed in a dictionary.
#  'PROJECT,SUBJ,SESSION,"{'T1-30:['T1_1.nii.gz','T1_2.nii.gz'],'T2-30':['T2_1.nii.gz']}"
SESSION_DB=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/edited_without_T2_PD_15s_predict_autoworkup_PREDICTHD.csv
# The desired output directory for this experiment
EXPERIMENT=20140219_TEMPLATE
# The base directory where all experiments of this type go
BASE_OUTPUT_DIR=/Shared/sinapse/CACHE
# Components of pipeline to run.  There are some branches of the workflow that are mostly for validation and experimentation.
# WORKFLOW_COMPONENTS=['BASIC','TISSUE_CLASSIFY','AUXLMK','SEGMENTATION']
WORKFLOW_COMPONENTS=['BASIC','TISSUE_CLASSIFY','AUXLMK']
PREVIOUS_EXPERIMENT=20140219_BASELINE
# Duplicate option for ATLAS_PATH
BUILD_DIR=/Shared/sinapse/sharedopt/20140201/RHEL6
### -------- THIS NEEDS TO BE SET CORRECTLY
# The path to the reference atlas space to be used in this analysis by all BRAINSTools
ATLAS_PATH=%(BUILD_DIR)s/NEP-build/ReferenceAtlas-build/Atlas/Atlas_20131115
# The path to the model files to be used by BCD.
#BCDMODELPATH=%(ATLASPATH)s/20111119_BCD


[PIPELINE]
GLOBAL_DATA_SINK_REWRITE=False
#GLOBAL_DATA_SINK_REWRITE=True


[CLUSTER]
# Necessary modules to load for jobs
MODULES=['python/2.7']
## The cluster queue to use for submitting "normal running" jobs.
QUEUE=-q HJ
## The cluster queue to use for submitting "long running" jobs.
QUEUE_LONG=-q HJ
# The QSTAT command for immediate update of values [ use 'qstat' if in doubt ]
QSTAT_IMMEDIATE=qstat
QSTAT_CACHED=qstat
# The QSTAT command for cached update of values ( to take load off of OGE server during heavy job usage ) [ use 'qstat' if in doubt ]
# QSTAT_IMMEDIATE_EXE=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/qstat_immediate.sh
# QSTAT_CACHED_EXE=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/qstat_cached.sh


[RHEL6]
BUILD_DIR=/Shared/sinapse/sharedopt/20140201/RHEL6
SOURCE_DIR=/Shared/sinapse/sharedopt/20140201/src
_GRAPHVIZ_BIN_DIR=/usr/bin/graphviz
# Optional: if you have a virtualenv this should be the path to the virtualenv
VIRTUALENV=%(BUILD_DIR)s/python_HD
CLUSTER=true
# The prefix to add to all image files in the $(SESSION_DB) to account for different file system mount points
MOUNT_PREFIX=
#ENVIRONMENT_VARIABLES  This is mostly needed for freesurfer
# Where to find Freesurfer base directory
ENVAR_DICT={'DUMMY':'JustATestEnv'}
############## -- You should not need to modify below here. ###########
_BRAINSTOOLS_BIN_PATH=%(BUILD_DIR)s/NEP-build/bin
# SimpleITK build directory (contains SimpleITK.py and _SimpleITK.so)
_SIMPLEITK_PYTHON_PATH=%(BUILD_DIR)s/NEP-build/lib
# Nipype source directory (contains nipype/ and setup.py)
_NIPYPE_CUSTOM_PATH=%(SOURCE_DIR)s/NAMICExternalProjects/SuperBuild/ExternalSources/NIPYPE
APPEND_PYTHONPATH=%(_NIPYPE_CUSTOM_PATH)s:%(_SIMPLEITK_PYTHON_PATH)s
APPEND_PATH=%(_BRAINSTOOLS_BIN_PATH)s:%(_SIMPLEITK_PYTHON_PATH)s:%(_GRAPHVIZ_BIN_DIR)s
